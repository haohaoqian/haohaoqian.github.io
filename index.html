<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Home page of Qianyue Hao">
	<link rel="stylesheet" href="./jemdoc.css" type="text/css">
	<title>Qianyue Hao's Homepage</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Qianyue Hao (郝千越)&nbsp;</h1></div>
	<h4>Ph.D. Candidate, <a href="https://www.ee.tsinghua.edu.cn/en/">Department of Electronic Engineering</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a></h4>
        <br>
        <p>
            Email: <a href="mailto:haoqianyue@hotmail.com">haoqianyue@hotmail.com</a> <br>
            CV: <a href="assets/CV_EN.pdf">[English]</a> <a href="assets/CV_CH.pdf">[Chinese]</a> <br> <br>
            <a href="https://scholar.google.com/citations?user=3qDk0OcAAAAJ">[Google Scholar]</a>
            <a href="https://www.researchgate.net/profile/Qianyue-Hao">[ResearchGate]</a>
        </p>
    </td>
</tr></tbody></table>


<h2>Biography</h2>
    <p> I am a fourth-year Ph.D. student at the <a href="https://www.ee.tsinghua.edu.cn/en/">Department of Electronic Engineering</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, advised by <a href="https://scholar.google.com/citations?user=kmgzPeQAAAAJ">Prof. Yong Li</a> and <a href="https://scholar.google.com/citations?user=Fks4s-wAAAAJ">Prof. Jian Yuan</a>. My research interests lie in <strong>Reinforcement Learning (RL) and Large Language Models (LLMs)</strong>. </p>    
    <p> Previously, I received my B.E. degree from the <a href="https://www.ee.tsinghua.edu.cn/en/">Department of Electronic Engineering</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> in June 2022.</p>


<h2>News</h2>
<ul>
	<li>
        <strong>2025-09</strong> I have a paper accepted by <strong>NeurIPS 2025</strong> as a <strong>spotlight</strong>!
    </li>
</ul>


<h2>Conference Publications</h2>
<ul>
	<li>
        <a href='https://arxiv.org/abs/2505.15293'>LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models</a> <br>
		<span style="color: red;">Spotlight paper (top 3.5% paper)</span> <br>
        <strong>Qianyue Hao*</strong>, Yiwen Song*, Qingmin Liao, Jian Yuan, Yong Li <br>
		The 38th International Conference on Neural Information Processing Systems <strong>(NeurIPS 2025)</strong> <br>
    </li>

	<li>
        <a href='https://proceedings.neurips.cc/paper_files/paper/2024/hash/5635925cf9d2274f338eb0dd5971e845-Abstract-Conference.html'>HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific Citation Prediction</a> <br>
        <strong>Qianyue Hao</strong>, Jingyang Fan, Fengli Xu, Jian Yuan, Yong Li <br>
		The 37th International Conference on Neural Information Processing Systems <strong>(NeurIPS 2024)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3690624.3709205'>CoopRide: Cooperate All Grids in City-Scale Ride-Hailing Dispatching with Multi-Agent Reinforcement Learning</a> <br>
        Jingwei Wang*, <strong>Qianyue Hao*</strong>, Wenzhen Huang, Xiaochen Fan, Qin Zhang, Zhentao Tang, Bin Wang, Jianye Hao, Yong Li <br>
		The 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2025)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3637528.3672052'>DyPS: Dynamic Parameter Sharing in Multi-Agent Reinforcement Learning for Spatio-Temporal Resource Allocation</a> <br>
        Jingwei Wang*, <strong>Qianyue Hao*</strong>, Wenzhen Huang, Xiaochen Fan, Zhentao Tang, Bin Wang, Jianye Hao, Yong Li <br>
		The 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2024)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3580305.3599359'>GAT-MF: Graph Attention Mean Field for Very Large Scale Multi-Agent Reinforcement Learning</a> <br>
        <strong>Qianyue Hao</strong>, Wenzhen Huang, Tao Feng, Jian Yuan, Yong Li <br>
		The 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2023)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3534678.3542679'>Reinforcement Learning Enhances the Experts: Large-scale COVID-19 Vaccine Allocation with Multi-factor Contact Network</a> <br>
        <strong>Qianyue Hao</strong>, Wenzhen Huang, Fengli Xu, Kun Tang, Yong Li <br>
		The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2022)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3447548.3467181'>Hierarchical Reinforcement Learning for Scarce Medical Resource Allocation with Imperfect Information</a> <br>
        <strong>Qianyue Hao</strong>, Fengli Xu, Lin Chen, Pan Hui, Yong Li <br>
		The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2021)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3394486.3412860'>Understanding the Urban Pandemic Spreading of COVID-19 with Real World Mobility Data</a> <br>
        <strong>Qianyue Hao*</strong>, Lin Chen*, Fengli Xu, Yong Li <br>
		The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2020)</strong> <br>
    </li>

	<li>
        <a href='https://arxiv.org/abs/2406.02126'>CityLight: A Neighborhood-inclusive Universal Model for Coordinated City-scale Traffic Signal Control</a> <br>
        Jinwei Zeng, Chao Yu, Xinyi Yang, Wenxuan Ao, <strong>Qianyue Hao</strong>, Jian Yuan, Yong Li, Yu Wang, Huazhong Yang <br>
		The 34th ACM International Conference on Information and Knowledge Management <strong>(CIKM 2025)</strong> <br>
    </li>
</ul>


<h2>Journal Publications</h2>
<ul>
	<li>
        <a href='https://www.cell.com/patterns/fulltext/S2666-3899(25)00218-1'>Toward Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models</a> <br>
        Fengli Xu*, <strong>Qianyue Hao*</strong>, Chenyang Shao*, Zefang Zong*, Yu Li*, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, Yuwei Yan, Qinglong Yang, Yiwen Song, Sijian Ren, Xinyuan Hu, Jie Feng, Chen Gao, Yong Li <br>
		<strong>Patterns</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3552436'>Hierarchical Multi-agent Model for Reinforced Medical Resource Allocation with Imperfect Information</a> <br>
        <strong>Qianyue Hao</strong>, Fengli Xu, Lin Chen, Pan Hui, Yong Li <br>
		ACM Transactions on Intelligent Systems and Technology <strong>(TIST)</strong> <br>
    </li>

	<li>
        <a href='https://dl.acm.org/doi/full/10.1145/3695986'>A Survey of Machine Learning for Urban Decision Making: Applications in Planning, Transportation, and Healthcare</a> <br>
        Yu Zheng, <strong>Qianyue Hao</strong>, Jingwei Wang, Changzheng Gao, Jinwei Chen, Depeng Jin, Yong Li <br>
		ACM Computing Surveys <strong>(CSUR)</strong> <br>
    </li>
</ul>


<h2>Preprints</h2>
<ul>
	<li>
        <a href='https://arxiv.org/abs/2505.14140'>RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning</a> <br>
        <strong>Qianyue Hao*</strong>, Sibo Li*, Jian Yuan, Yong Li <br>
    </li>

	<li>
        <a href='https://arxiv.org/abs/2509.21027'>KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models</a> <br>
        Sibo Li*, <strong>Qianyue Hao*</strong>, Yu Shang, Yong Li <br>
    </li>

	<li>
        <a href='https://arxiv.org/abs/2509.21044'>Reinforcement Learning Fine-Tuning Enhances Activation Intensity and Diversity in the Internal Circuitry of LLMs</a> <br>
        Honglin Zhang*, <strong>Qianyue Hao*</strong>, Fengli Xu, Yong Li <br>
    </li>

	<li>
        <a href='https://arxiv.org/abs/2505.15306'>Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One</a> <br>
        Yiwen Song*, <strong>Qianyue Hao*</strong>, Qingmin Liao, Jian Yuan, Yong Li <br>
    </li>

	<li>
        <a href='https://arxiv.org/abs/2412.07727'>AI Expands Scientists' Impact but Contracts Science's Focus</a> <br>
        <strong>Qianyue Hao</strong>, Fengli Xu, Yong Li, James Evans <br>
    </li>

	<li>
        <a href='https://www.researchgate.net/publication/395648618_Reinforcement_Learning_in_the_Era_of_Large_Language_Models_Challenges_and_Opportunities'>Reinforcement Learning in the Era of Large Language Models: Challenges and Opportunities</a> <br>
        <strong>Qianyue Hao</strong>, Lin Chen, Xiaoqian Qi, Yuan Yuan, Zefang Zong, Hongyi Chen, Keyu Zhao, Shengyuan Wang, Yunke Zhang, Jian Yuan, Yong Li <br>
    </li>

	<li>
        <a href='https://arxiv.org/abs/2411.14491'>A Survey on Human-Centric LLMs</a> <br>
        Jing Yi Wang, Nicholas Sukiennik, Tong Li, Weikang Su, <strong>Qianyue Hao</strong>, Jingbo Xu, Zihan Huang, Fengli Xu, Yong Li <br>
    </li>
</ul>


<h2>Academic Services</h2>
<ul>
	<li>
        I have served as a reviewer for the following conferences: NeurIPS (2025), ICML (2025), ICLR (2025-2026), AAAI (2026), KDD (2023-2026), WWW (2026), CIKM (2025), SDM (2023) <br>
    </li>

    <li>
        I have served as a reviewer for the following journals: IMWUT (2025) <br>
    </li>
</ul>


<h2>Awards</h2>
<ul>
	<li>
        <strong>2023-10</strong> Scholarship for Graduate Students (研究生综合奖学金), Department of Electronic Engineering, Tsinghua University
    </li>

	<li>
        <strong>2022-06</strong> Outstanding Undergraduate Thesis Award (本科优秀毕业论文), Tsinghua University
    </li>

	<li>
        <strong>2021-10</strong> National Scholarship for Undergraduate Students (本科生国家奖学金), Ministry of Education of the PRC
    </li>

	<li>
        <strong>2020-10</strong> Scholarship for Undergraduate Students (本科生综合奖学金), Tsinghua University
    </li>
</ul>
</div>


<div id="footer">
	<div id="footer-text"></div>
</div>
* indicates co-first authors. <br>
&copy 2025 Qianyue Hao

</body>

</html>
